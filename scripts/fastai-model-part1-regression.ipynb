{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TabularLearner with part 1\n",
    "\n",
    "In this notebook data generated from this [kernel](https://www.kaggle.com/keremt/fastai-feature-engineering-part1-6160-feats/) is used during modeling. Data can also be found as a Kaggle [dataset](https://www.kaggle.com/keremt/dsbowl2019-feng-part1). This notebook is part 1 of series of notebooks that will model data from corresponding feature engineering kernels as we keep adding hopefully some creative features :)\n",
    "\n",
    "**Important Note:** Feature generation for test data will happen online since private test set is not publicly available for precomputation!\n",
    "\n",
    "This notebook will give a LB around: 0.506 (score can vary but it's solely for baseline purposes)\n",
    "\n",
    "**To see how features are generated in more detail:** [Feature Engineering Part 1 Notebook](https://www.kaggle.com/keremt/fastai-feature-engineering-part1-6160-feats/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('../data-science-bowl-2019/sample_submission.csv'),\n",
       " PosixPath('../data-science-bowl-2019/specs.csv'),\n",
       " PosixPath('../data-science-bowl-2019/dsbowl2019-feng-part1'),\n",
       " PosixPath('../data-science-bowl-2019/train_labels.csv'),\n",
       " PosixPath('../data-science-bowl-2019/train.csv'),\n",
       " PosixPath('../data-science-bowl-2019/test.csv'),\n",
       " PosixPath('../data-science-bowl-2019/working')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastai.core import *\n",
    "Path.read_csv = lambda o: pd.read_csv(o)\n",
    "input_path = Path(\"../data-science-bowl-2019\")\n",
    "pd.options.display.max_columns=200\n",
    "pd.options.display.max_rows=200\n",
    "input_path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_features_part1 = pd.read_csv(\"../data-science-bowl-2019/dsbowl2019-feng-part1/train_with_features_part1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_subdf = (input_path/'sample_submission.csv').read_csv()\n",
    "# specs_df = (input_path/\"specs.csv\").read_csv()\n",
    "# train_labels_df = (input_path/\"train_labels.csv\").read_csv()\n",
    "# train_df = (input_path/\"train.csv\").read_csv()\n",
    "test_df = (input_path/\"test.csv\").read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 2), (1156414, 11), (17690, 6191))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_subdf.shape, test_df.shape, train_with_features_part1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features (part1)\n",
    "\n",
    "Basically here we redefine the feature generation code for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular import *\n",
    "import types\n",
    "\n",
    "stats = [\"median\",\"mean\",\"sum\",\"min\",\"max\"]\n",
    "UNIQUE_COL_VALS = pickle.load(open(input_path/\"dsbowl2019-feng-part1/UNIQUE_COL_VALS.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event_ids 379\n",
      "media_types 4\n",
      "titles 44\n",
      "worlds 4\n",
      "event_codes 42\n"
     ]
    }
   ],
   "source": [
    "for k in UNIQUE_COL_VALS.__dict__.keys():\n",
    "    print(k, len(UNIQUE_COL_VALS.__dict__[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def array_output(f):\n",
    "    def inner(*args, **kwargs): return array(listify(f(*args, **kwargs))).flatten()\n",
    "    return inner\n",
    "\n",
    "feature_funcs = []\n",
    "\n",
    "@array_output\n",
    "def time_elapsed_since_hist_begin(df):\n",
    "    \"total time passed until assessment begin\"\n",
    "    return df['timestampElapsed'].max() - df['timestampElapsed'].min()\n",
    "\n",
    "feature_funcs.append(time_elapsed_since_hist_begin)\n",
    "\n",
    "@array_output\n",
    "def time_elapsed_since_each(df, types, dfcol):\n",
    "    \"time since last occurence of each types, if type not seen then time since history begin\"\n",
    "    types = UNIQUE_COL_VALS.__dict__[types]\n",
    "    last_elapsed = df['timestampElapsed'].max()\n",
    "    _d = dict(df.iloc[:-1].groupby(dfcol)['timestampElapsed'].max())\n",
    "    return [last_elapsed - _d[t] if t in _d else time_elapsed_since_hist_begin(df)[0] for t in types]\n",
    "\n",
    "feature_funcs.append(partial(time_elapsed_since_each, types=\"media_types\", dfcol=\"type\"))\n",
    "feature_funcs.append(partial(time_elapsed_since_each, types=\"titles\", dfcol=\"title\"))\n",
    "feature_funcs.append(partial(time_elapsed_since_each, types=\"event_ids\", dfcol=\"event_id\"))\n",
    "feature_funcs.append(partial(time_elapsed_since_each, types=\"worlds\", dfcol=\"world\"))\n",
    "feature_funcs.append(partial(time_elapsed_since_each, types=\"event_codes\", dfcol=\"event_code\"))\n",
    "\n",
    "@array_output\n",
    "def countfreqhist(df, types, dfcol, freq=False):\n",
    "    \"count or freq of types until assessment begin\"\n",
    "    types = UNIQUE_COL_VALS.__dict__[types]\n",
    "    _d = dict(df[dfcol].value_counts(normalize=(True if freq else False)))\n",
    "    return [_d[t] if t in _d else 0 for t in types]\n",
    "\n",
    "feature_funcs.append(partial(countfreqhist, types=\"media_types\", dfcol=\"type\", freq=False))\n",
    "feature_funcs.append(partial(countfreqhist, types=\"media_types\", dfcol=\"type\", freq=True))\n",
    "\n",
    "feature_funcs.append(partial(countfreqhist, types=\"titles\", dfcol=\"title\", freq=False))\n",
    "feature_funcs.append(partial(countfreqhist, types=\"titles\", dfcol=\"title\", freq=True))\n",
    "\n",
    "feature_funcs.append(partial(countfreqhist, types=\"event_ids\", dfcol=\"event_id\", freq=False))\n",
    "feature_funcs.append(partial(countfreqhist, types=\"event_ids\", dfcol=\"event_id\", freq=True))\n",
    "\n",
    "feature_funcs.append(partial(countfreqhist, types=\"worlds\", dfcol=\"world\", freq=False))\n",
    "feature_funcs.append(partial(countfreqhist, types=\"worlds\", dfcol=\"world\", freq=True))\n",
    "\n",
    "feature_funcs.append(partial(countfreqhist, types=\"event_codes\", dfcol=\"event_code\", freq=False))\n",
    "feature_funcs.append(partial(countfreqhist, types=\"event_codes\", dfcol=\"event_code\", freq=True))\n",
    "\n",
    "@array_output\n",
    "def overall_event_count_stats(df):\n",
    "    \"overall event count stats until assessment begin\"\n",
    "    return df['event_count'].agg(stats)\n",
    "feature_funcs.append(overall_event_count_stats)\n",
    "\n",
    "@array_output\n",
    "def event_count_stats_each(df, types, dfcol):\n",
    "    \"event count stats per media types until assessment begin, all zeros if media type missing for user\"\n",
    "    types = UNIQUE_COL_VALS.__dict__[types]\n",
    "    _stats_df = df.groupby(dfcol)['event_count'].agg(stats)\n",
    "    _d = dict(zip(_stats_df.reset_index()[dfcol].values, _stats_df.values))\n",
    "    return [_d[t] if t in _d else np.zeros(len(stats)) for t in types]\n",
    "feature_funcs.append(partial(event_count_stats_each, types=\"media_types\", dfcol=\"type\"))\n",
    "feature_funcs.append(partial(event_count_stats_each, types=\"titles\", dfcol=\"title\"))\n",
    "feature_funcs.append(partial(event_count_stats_each, types=\"event_ids\", dfcol=\"event_id\"))\n",
    "feature_funcs.append(partial(event_count_stats_each, types=\"worlds\", dfcol=\"world\"))\n",
    "feature_funcs.append(partial(event_count_stats_each, types=\"event_codes\", dfcol=\"event_code\"))\n",
    "\n",
    "@array_output\n",
    "def overall_session_game_time_stats(df):\n",
    "    \"overall session game time stats until assessment begin\"\n",
    "    return df['game_time'].agg(stats)\n",
    "feature_funcs.append(overall_session_game_time_stats)\n",
    "\n",
    "@array_output\n",
    "def session_game_time_stats_each(df, types, dfcol):\n",
    "    \"session game time stats per media types until assessment begin, all zeros if missing for user\"\n",
    "    types = UNIQUE_COL_VALS.__dict__[types]\n",
    "    _stats_df = df.groupby(dfcol)['game_time'].agg(stats)\n",
    "    _d = dict(zip(_stats_df.reset_index()[dfcol].values, _stats_df.values))\n",
    "    return [_d[t] if t in _d else np.zeros(len(stats)) for t in types]\n",
    "feature_funcs.append(partial(session_game_time_stats_each, types=\"media_types\", dfcol=\"type\"))\n",
    "feature_funcs.append(partial(session_game_time_stats_each, types=\"titles\", dfcol=\"title\"))\n",
    "feature_funcs.append(partial(session_game_time_stats_each, types=\"event_ids\", dfcol=\"event_id\"))\n",
    "feature_funcs.append(partial(session_game_time_stats_each, types=\"worlds\", dfcol=\"world\"))\n",
    "feature_funcs.append(partial(session_game_time_stats_each, types=\"event_codes\", dfcol=\"event_code\"))\n",
    "\n",
    "len(feature_funcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Feature Engineering\n",
    "\n",
    "Test set in LB and Private LB is different than what is publicly shared. So feature engineering and inference for test set should be done online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sorted_user_df(df, ins_id):\n",
    "    \"extract sorted data for a given installation id and add datetime features\"\n",
    "    _df = df[df.installation_id == ins_id].sort_values(\"timestamp\").reset_index(drop=True)\n",
    "    add_datepart(_df, \"timestamp\", time=True)\n",
    "    return _df\n",
    "\n",
    "def get_test_assessment_start_idxs(df): \n",
    "    return list(df.sort_values(\"timestamp\")\n",
    "                  .query(\"type == 'Assessment' & event_code == 2000\")\n",
    "                  .groupby(\"installation_id\").tail(1).index)\n",
    "\n",
    "def get_test_feats_row(idx, i):\n",
    "    \"get all faeatures by an installation start idx\"\n",
    "    ins_id = test_df.loc[idx, \"installation_id\"]\n",
    "    _df = get_sorted_user_df(test_df, ins_id)\n",
    "    assessment_row = _df.iloc[-1]\n",
    "    row_feats = np.concatenate([f(_df) for f in feature_funcs])\n",
    "    feat_row = pd.Series(row_feats, index=[f\"static_feat{i}\"for i in range(len(row_feats))])\n",
    "    row = pd.concat([assessment_row, feat_row])\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering part 1\n",
    "start_idxs = get_test_assessment_start_idxs(test_df)\n",
    "res = parallel(get_test_feats_row, start_idxs)\n",
    "test_with_features_df = pd.concat(res,1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_with_features_part1 = test_with_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see train and test have same features\n",
    "num_test_feats = [c for c in test_with_features_df.columns if c.startswith(\"static\")]\n",
    "num_train_feats = [c for c in train_with_features_part1.columns if c.startswith(\"static\")]\n",
    "assert num_train_feats == num_test_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudolabeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudolabels = pd.read_csv('for_pseudolabeling.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_features_part1.drop(columns=['Unnamed: 0'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_with_features_part1_pseudo = test_with_features_part1.copy()\n",
    "test_with_features_part1_pseudo['accuracy_group'] = np.mean(pseudolabels, axis=1)\n",
    "test_with_features_part1_pseudo['accuracy'] = np.zeros_like(pseudolabels['lgb']) * np.nan\n",
    "test_with_features_part1_pseudo['num_correct'] = np.zeros_like(pseudolabels['lgb']) * np.nan\n",
    "test_with_features_part1_pseudo['num_incorrect'] = np.zeros_like(pseudolabels['lgb']) * np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_features_part1 = pd.concat([train_with_features_part1,\n",
    "                                       test_with_features_part1_pseudo],\n",
    "                                      axis=0,\n",
    "                                      sort=True).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_features_part1.drop(columns=['index'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TabularLearner Model\n",
    "\n",
    "Here we use a single validation but in later stages once we finalize features we should use cross-validation. We don't over optimize the model or do any hyperparameter search since the whole purpose is to get a baseline and build on top of it in upcoming parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18690, 6190), (1000, 6186))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_with_features_part1.shape, test_with_features_part1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([    3,     4,     5,     6,     7,     8,     9,    10,    11,\n",
       "               12,\n",
       "            ...\n",
       "            18641, 18645, 18647, 18656, 18659, 18668, 18674, 18687, 18688,\n",
       "            18689],\n",
       "           dtype='int64', length=3488)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create validation set - split by installation_id\n",
    "np.random.seed(42)\n",
    "valid_ids = (np.random.choice(train_with_features_part1.installation_id.unique(),\n",
    "                              int(len(train_with_features_part1)*0.05)))\n",
    "valid_idx = (train_with_features_part1[train_with_features_part1.installation_id.isin(valid_ids)].index); valid_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "cat_names = ['title','world']\n",
    "cont_names = [c for c in train_with_features_part1.columns if c.startswith(\"static_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-9b816b96a550>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrainset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_numpy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "# from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# trainset = TensorDataset(torch.from_numpy(train_numpy[train_idxs, :]))\n",
    "# train_loader = DataLoader(trainset, batch_size=256, shuffle=True, num_workers=-1)\n",
    "\n",
    "# validset = TensorDataset(torch.from_numpy(train_numpy[valid_idx, :]))\n",
    "# valid_loader = DataLoader(validset, batch_size=256, shuffle=False, num_workers=-1)\n",
    "\n",
    "# testset = TensorDataset(torch.from_numpy(test_numpy))\n",
    "# test_loader = DataLoader(testset, batch_size=256, shuffle=False, num_workers=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import  Pool\n",
    "\n",
    "\n",
    "def parallelize_dataframe(df, func, n_cores=4):\n",
    "    df_split = np.array_split(df, n_cores, axis=1)\n",
    "    pool = Pool(n_cores)\n",
    "    df = pd.concat(pool.map(func, df_split), axis=1)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_df_type(df, dtype=float):\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].astype(dtype)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44.4 s, sys: 31.4 s, total: 1min 15s\n",
      "Wall time: 4min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "train_with_features_part1_type = parallelize_dataframe(train_with_features_part1[cont_names], change_df_type, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_add = list(set(train_with_features_part1.columns) - set(train_with_features_part1_type.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in columns_to_add:\n",
    "    train_with_features_part1_type[col] = train_with_features_part1[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "procs = [FillMissing, Categorify, Normalize]\n",
    "data = TabularDataBunch.from_df(path=\".\", df=train_with_features_part1_type, dep_var=\"accuracy_group\", \n",
    "                                valid_idx=valid_idx, procs=procs, cat_names=cat_names, cont_names=cont_names)\n",
    "\n",
    "data.add_test(TabularList.from_df(test_with_features_part1, cat_names=cat_names, cont_names=cont_names));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='36' class='' max='100', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      36.00% [36/100 03:50<06:49]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.889248</td>\n",
       "      <td>1.606252</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.758725</td>\n",
       "      <td>1.562617</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.708034</td>\n",
       "      <td>1.538743</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.621285</td>\n",
       "      <td>1.531267</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.587671</td>\n",
       "      <td>1.521891</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.547718</td>\n",
       "      <td>1.536903</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.514013</td>\n",
       "      <td>1.525254</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.458650</td>\n",
       "      <td>1.523725</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.372522</td>\n",
       "      <td>1.463661</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.287194</td>\n",
       "      <td>1.316368</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.225786</td>\n",
       "      <td>1.257353</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.171306</td>\n",
       "      <td>1.225466</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.124077</td>\n",
       "      <td>1.169841</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.121398</td>\n",
       "      <td>1.165117</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.103971</td>\n",
       "      <td>1.162684</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.050907</td>\n",
       "      <td>1.146180</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.047749</td>\n",
       "      <td>1.129241</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.039852</td>\n",
       "      <td>1.134421</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.048217</td>\n",
       "      <td>1.125785</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.042201</td>\n",
       "      <td>1.118796</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.008239</td>\n",
       "      <td>1.142386</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.025847</td>\n",
       "      <td>1.146773</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.005425</td>\n",
       "      <td>1.164004</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.979278</td>\n",
       "      <td>1.169183</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.980956</td>\n",
       "      <td>1.126953</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.937291</td>\n",
       "      <td>1.097645</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.976001</td>\n",
       "      <td>1.136257</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.931543</td>\n",
       "      <td>1.152671</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.950284</td>\n",
       "      <td>1.132783</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.951286</td>\n",
       "      <td>1.118764</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.940292</td>\n",
       "      <td>1.133255</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.946611</td>\n",
       "      <td>1.144214</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.913590</td>\n",
       "      <td>1.151968</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.907783</td>\n",
       "      <td>1.128249</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.905662</td>\n",
       "      <td>1.160354</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.887686</td>\n",
       "      <td>1.139215</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='55' class='' max='55', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [55/55 00:01<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: early stopping\n"
     ]
    }
   ],
   "source": [
    "# fit\n",
    "from fastai.callbacks import EarlyStoppingCallback, SaveModelCallback\n",
    "learner = tabular_learner(data, [512, 256, 128, 256, 128, 64], y_range=(0., 3), ps=0.6, emb_drop=0)\n",
    "learner.fit_one_cycle(100, 3e-3, callbacks=[EarlyStoppingCallback(learner,\n",
    "                                                                  monitor='valid_loss',\n",
    "                                                                  patience=10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Validation Score\n",
    "\n",
    "Again, we don't search for optimal coefficients since main purpose is to create a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qwk(a1, a2):\n",
    "    \"\"\"\n",
    "    Source: https://www.kaggle.com/c/data-science-bowl-2019/discussion/114133#latest-660168\n",
    "\n",
    "    :param a1:\n",
    "    :param a2:\n",
    "    :param max_rat:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    max_rat = 3\n",
    "    a1 = np.asarray(a1, dtype=int)\n",
    "    a2 = np.asarray(a2, dtype=int)\n",
    "\n",
    "    hist1 = np.zeros((max_rat + 1, ))\n",
    "    hist2 = np.zeros((max_rat + 1, ))\n",
    "\n",
    "    o = 0\n",
    "    for k in range(a1.shape[0]):\n",
    "        i, j = a1[k], a2[k]\n",
    "        hist1[i] += 1\n",
    "        hist2[j] += 1\n",
    "        o +=  (i - j) * (i - j)\n",
    "\n",
    "    e = 0\n",
    "    for i in range(max_rat + 1):\n",
    "        for j in range(max_rat + 1):\n",
    "            e += hist1[i] * hist2[j] * (i - j) * (i - j)\n",
    "\n",
    "    e = e / a1.shape[0]\n",
    "\n",
    "    return 1 - o / e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from functools import partial\n",
    "# import scipy as sp\n",
    "# class OptimizedRounder(object):\n",
    "#     \"\"\"\n",
    "#     An optimizer for rounding thresholds\n",
    "#     to maximize Quadratic Weighted Kappa (QWK) score\n",
    "#     # https://www.kaggle.com/naveenasaithambi/optimizedrounder-improved\n",
    "#     \"\"\"\n",
    "#     def __init__(self):\n",
    "#         self.coef_ = 0\n",
    "\n",
    "#     def _kappa_loss(self, coef, X, y):\n",
    "#         \"\"\"\n",
    "#         Get loss according to\n",
    "#         using current coefficients\n",
    "        \n",
    "#         :param coef: A list of coefficients that will be used for rounding\n",
    "#         :param X: The raw predictions\n",
    "#         :param y: The ground truth labels\n",
    "#         \"\"\"\n",
    "#         X_p = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1/4, 2/4, 3/4])\n",
    "\n",
    "#         return -qwk(y, X_p)\n",
    "\n",
    "#     def fit(self, X, y):\n",
    "#         \"\"\"\n",
    "#         Optimize rounding thresholds\n",
    "        \n",
    "#         :param X: The raw predictions\n",
    "#         :param y: The ground truth labels\n",
    "#         \"\"\"\n",
    "#         loss_partial = partial(self._kappa_loss, X=X, y=y)\n",
    "#         initial_coef = [0.5/4, 1.5/4, 2.5/4]\n",
    "#         self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n",
    "\n",
    "#     def predict(self, X, coef):\n",
    "#         \"\"\"\n",
    "#         Make predictions with specified thresholds\n",
    "        \n",
    "#         :param X: The raw predictions\n",
    "#         :param coef: A list of coefficients that will be used for rounding\n",
    "#         \"\"\"\n",
    "#         return pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1/4, 2/4, 3/4])\n",
    "\n",
    "\n",
    "#     def coefficients(self):\n",
    "#         \"\"\"\n",
    "#         Return the optimized coefficients\n",
    "#         \"\"\"\n",
    "#         return self.coef_['x']\n",
    "\n",
    "from functools import partial\n",
    "import scipy as sp\n",
    "class OptimizedRounder(object):\n",
    "    \"\"\"\n",
    "    An optimizer for rounding thresholds\n",
    "    to maximize Quadratic Weighted Kappa (QWK) score\n",
    "    # https://www.kaggle.com/naveenasaithambi/optimizedrounder-improved\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _kappa_loss(self, coef, X, y):\n",
    "        \"\"\"\n",
    "        Get loss according to\n",
    "        using current coefficients\n",
    "        \n",
    "        :param coef: A list of coefficients that will be used for rounding\n",
    "        :param X: The raw predictions\n",
    "        :param y: The ground truth labels\n",
    "        \"\"\"\n",
    "        X_p = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3])\n",
    "\n",
    "        return -qwk(y, X_p)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Optimize rounding thresholds\n",
    "        \n",
    "        :param X: The raw predictions\n",
    "        :param y: The ground truth labels\n",
    "        \"\"\"\n",
    "        loss_partial = partial(self._kappa_loss, X=X, y=y)\n",
    "        initial_coef = [0.5, 1.5, 2.5]\n",
    "        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n",
    "\n",
    "    def predict(self, X, coef):\n",
    "        \"\"\"\n",
    "        Make predictions with specified thresholds\n",
    "        \n",
    "        :param X: The raw predictions\n",
    "        :param coef: A list of coefficients that will be used for rounding\n",
    "        \"\"\"\n",
    "        return pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3])\n",
    "\n",
    "\n",
    "    def coefficients(self):\n",
    "        \"\"\"\n",
    "        Return the optimized coefficients\n",
    "        \"\"\"\n",
    "        return self.coef_['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "# get valid preds\n",
    "preds, targs = learner.get_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "optR = OptimizedRounder()\n",
    "optR.fit(preds.reshape(-1,), targs)\n",
    "coefs = optR.coefficients()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.630145, 1.448402, 2.291683])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft2hard(o):\n",
    "    if o < coefs[0]: return 0\n",
    "    elif o < coefs[1]: return 1\n",
    "    elif o < coefs[2]: return 2\n",
    "    else: return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get accuracy_group for preds and targs\n",
    "_preds = array([soft2hard(o.item()) for o in preds])\n",
    "_targs = array(train_with_features_part1.iloc[valid_idx]['accuracy_group'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "_targs = array([soft2hard(targ) for targ in _targs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4998358824055993"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see validation score\n",
    "cohen_kappa_score(_targs, _preds, weights=\"quadratic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.5223101490886595"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get test preds\n",
    "preds,targs=learner.get_preds(DatasetType.Test)\n",
    "_preds = array([soft2hard(o.item()) for o in preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3: 472, 2: 311, 1: 130, 0: 87})"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get installation ids for test set\n",
    "test_ids = test_with_features_part1['installation_id'].values; len(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate installation_id : pred dict\n",
    "test_preds_dict = dict(zip(test_ids, _preds)); len(test_preds_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create submission\n",
    "sample_subdf['accuracy_group'] = sample_subdf.installation_id.map(test_preds_dict)\n",
    "sample_subdf['accuracy_group'] = sample_subdf['accuracy_group'].fillna(3)\n",
    "sample_subdf.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
